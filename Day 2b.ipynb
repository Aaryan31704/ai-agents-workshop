{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6d90df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Setup and authentication complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "try:\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "    print(\"âœ… Setup and authentication complete.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"ðŸ”‘ Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "363b4ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ADK components imported successfully.\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "from google.genai import types\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "from google.adk.tools.mcp_tool.mcp_toolset import McpToolset\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.tools.mcp_tool.mcp_session_manager import StdioConnectionParams\n",
    "from mcp import StdioServerParameters\n",
    "\n",
    "from google.adk.apps.app import App, ResumabilityConfig\n",
    "from google.adk.tools.function_tool import FunctionTool\n",
    "\n",
    "\n",
    "\n",
    "print(\"âœ… ADK components imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd608044",
   "metadata": {},
   "outputs": [],
   "source": [
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a045472",
   "metadata": {},
   "source": [
    "# 1.1 Model Context Protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ddc7e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… MCP Tool created\n",
      "ðŸ“ MCP server logs will be written to: C:\\Users\\aarya\\AppData\\Local\\Temp\\tmpq9uic0h2.log\n"
     ]
    }
   ],
   "source": [
    "# Workaround for Windows/Jupyter: Use a file for stderr instead of Jupyter's stream\n",
    "# Jupyter's stderr doesn't support fileno(), which MCP needs for subprocess creation\n",
    "import sys\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# Create a temporary file for stderr that supports fileno()\n",
    "# This avoids the \"UnsupportedOperation: fileno\" error in Jupyter\n",
    "stderr_file_path = tempfile.NamedTemporaryFile(mode='w+', delete=False, suffix='.log')\n",
    "stderr_file_path.close()\n",
    "\n",
    "# Open the file for writing (will be kept open for MCP to use)\n",
    "stderr_file = open(stderr_file_path.name, 'w', buffering=1)  # Line buffered\n",
    "\n",
    "try:\n",
    "    mcp_kaggle_server = McpToolset(\n",
    "        connection_params=StdioConnectionParams(\n",
    "            server_params=StdioServerParameters(\n",
    "                command='npx',\n",
    "                args=[\n",
    "                    '-y',\n",
    "                    'mcp-remote',\n",
    "                    'https://www.kaggle.com/mcp'\n",
    "                ],\n",
    "            ),\n",
    "            timeout=30,\n",
    "        ),\n",
    "        errlog=stderr_file,  # Use file instead of sys.stderr\n",
    "    )\n",
    "    print(\"âœ… MCP Tool created\")\n",
    "    print(f\"ðŸ“ MCP server logs will be written to: {stderr_file_path.name}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating MCP tool: {e}\")\n",
    "    stderr_file.close()\n",
    "    # Clean up temp file on error\n",
    "    try:\n",
    "        os.unlink(stderr_file_path.name)\n",
    "    except:\n",
    "        pass\n",
    "    raise\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a2cfe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mcp_kaggle_server_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"mcp_kaggle_server_agent\",\n",
    "    instruction=\"Use the MCP Tool to search and download Kaggle datasets, Access notebook metadata, Query competition information etc., \",\n",
    "    tools=[mcp_kaggle_server],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09ce6f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "App name mismatch detected. The runner is configured with app name \"InMemoryRunner\", but the root agent was loaded from \"C:\\Users\\aarya\\Desktop\\Aaryan\\Projects\\Agents\\ai-agents-workshop\\agentenv\\Lib\\site-packages\\google\\adk\\agents\", which implies app name \"agents\".\n"
     ]
    }
   ],
   "source": [
    "from google.adk.runners import InMemoryRunner\n",
    "\n",
    "runner = InMemoryRunner(agent=mcp_kaggle_server_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32bb0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ### Created new session: kaggle_test_session\n",
      "\n",
      "User > Search for datasets about machine learning on Kaggle\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aarya\\Desktop\\Aaryan\\Projects\\Agents\\ai-agents-workshop\\agentenv\\Lib\\site-packages\\google\\adk\\tools\\mcp_tool\\mcp_tool.py:101: UserWarning: [EXPERIMENTAL] BaseAuthenticatedTool: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  super().__init__(\n",
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mcp_kaggle_server_agent > [Calling tool: search_datasets({'request': {'search': 'machine learning'}})]\n",
      "mcp_kaggle_server_agent > [Tool result: {'content': [{'type': 'text', 'text': '{\\n  \"datasets\": [\\n    {\\n      \"id\": 228,\\n      \"ref\": \"uc...]\n",
      "\n",
      "âœ… Request completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Try a Kaggle-specific query instead\n",
    "try:\n",
    "    response = await runner.run_debug(\n",
    "        \"Search for datasets about machine learning on Kaggle\", \n",
    "        verbose=True,\n",
    "        session_id=\"kaggle_test_session\"\n",
    "    )\n",
    "    print(\"\\nâœ… Request completed successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Make sure Node.js is installed and in PATH\")\n",
    "    print(\"2. Try restarting your Jupyter kernel\")\n",
    "    print(\"3. Check if 'mcp-remote' package is accessible via npx\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8694ee20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Extracting dataset information from the response...\n",
      "\n",
      "âœ… Found 20 datasets from Kaggle\n",
      "\n",
      "======================================================================\n",
      "\n",
      "ðŸ“¦ Dataset 1:\n",
      "   ID: 228\n",
      "   Ref: uciml/pima-indians-diabetes-database\n",
      "   Title: Pima Indians Diabetes Database\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 2:\n",
      "   ID: 180\n",
      "   Ref: uciml/breast-cancer-wisconsin-data\n",
      "   Title: Breast Cancer Wisconsin (Diagnostic) Data Set\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 3:\n",
      "   ID: 4458\n",
      "   Ref: uciml/red-wine-quality-cortez-et-al-2009\n",
      "   Title: Red Wine Quality\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 4:\n",
      "   ID: 19\n",
      "   Ref: uciml/iris\n",
      "   Title: Iris Species\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 5:\n",
      "   ID: 478\n",
      "   Ref: uciml/mushroom-classification\n",
      "   Title: Mushroom Classification\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 6:\n",
      "   ID: 251\n",
      "   Ref: uciml/student-alcohol-consumption\n",
      "   Title: Student Alcohol Consumption\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 7:\n",
      "   ID: 310\n",
      "   Ref: mlg-ulb/creditcardfraud\n",
      "   Title: Credit Card Fraud Detection\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 8:\n",
      "   ID: 70947\n",
      "   Ref: kaggle/kaggle-survey-2018\n",
      "   Title: 2018 Kaggle Machine Learning & Data Science Survey\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 9:\n",
      "   ID: 483\n",
      "   Ref: uciml/sms-spam-collection-dataset\n",
      "   Title: SMS Spam Collection Dataset\n",
      "\n",
      "\n",
      "ðŸ“¦ Dataset 10:\n",
      "   ID: 654897\n",
      "   Ref: kaushil268/disease-prediction-using-machine-learning\n",
      "   Title: Disease Prediction Using Machine Learning \n",
      "\n",
      "... and 10 more datasets\n",
      "======================================================================\n",
      "\n",
      "ðŸ’¡ These datasets came from Kaggle via the MCP server\n",
      "   Tool used: search_datasets\n",
      "   Search query: 'machine learning'\n"
     ]
    }
   ],
   "source": [
    "# Extract and display the datasets from the response\n",
    "import json\n",
    "\n",
    "print(\"ðŸ“Š Extracting dataset information from the response...\\n\")\n",
    "\n",
    "# The datasets came from the Kaggle MCP server via the search_datasets tool\n",
    "# Let's extract them from the response events\n",
    "datasets_found = []\n",
    "\n",
    "for event in response:\n",
    "    if hasattr(event, 'content') and event.content and event.content.parts:\n",
    "        for part in event.content.parts:\n",
    "            # Check for function response (tool results)\n",
    "            if hasattr(part, 'function_response') and part.function_response:\n",
    "                result = part.function_response.response\n",
    "                \n",
    "                # MCP tool result format\n",
    "                if isinstance(result, dict) and 'content' in result:\n",
    "                    content = result['content']\n",
    "                    if isinstance(content, list) and len(content) > 0:\n",
    "                        text_content = content[0].get('text', '')\n",
    "                        try:\n",
    "                            # Parse the JSON response\n",
    "                            datasets_data = json.loads(text_content)\n",
    "                            datasets_found = datasets_data.get('datasets', [])\n",
    "                            \n",
    "                            print(f\"âœ… Found {len(datasets_found)} datasets from Kaggle\\n\")\n",
    "                            print(\"=\" * 70)\n",
    "                            \n",
    "                            # Display each dataset\n",
    "                            for i, dataset in enumerate(datasets_found[:10], 1):  # Show first 10\n",
    "                                print(f\"\\nðŸ“¦ Dataset {i}:\")\n",
    "                                print(f\"   ID: {dataset.get('id', 'N/A')}\")\n",
    "                                print(f\"   Ref: {dataset.get('ref', 'N/A')}\")\n",
    "                                if 'title' in dataset:\n",
    "                                    print(f\"   Title: {dataset.get('title', 'N/A')}\")\n",
    "                                if 'size' in dataset:\n",
    "                                    print(f\"   Size: {dataset.get('size', 'N/A')}\")\n",
    "                                print()\n",
    "                            \n",
    "                            if len(datasets_found) > 10:\n",
    "                                print(f\"... and {len(datasets_found) - 10} more datasets\")\n",
    "                            \n",
    "                            print(\"=\" * 70)\n",
    "                            print(f\"\\nðŸ’¡ These datasets came from Kaggle via the MCP server\")\n",
    "                            print(f\"   Tool used: search_datasets\")\n",
    "                            print(f\"   Search query: 'machine learning'\")\n",
    "                            \n",
    "                        except json.JSONDecodeError as e:\n",
    "                            print(f\"âš ï¸ Could not parse JSON: {e}\")\n",
    "                            print(f\"Raw content (first 500 chars): {text_content[:500]}\")\n",
    "\n",
    "if not datasets_found:\n",
    "    print(\"âš ï¸ No datasets found in response. The tool may have returned data in a different format.\")\n",
    "    print(\"\\nFull response structure:\")\n",
    "    for i, event in enumerate(response[:3]):  # Show first 3 events\n",
    "        print(f\"\\nEvent {i}: {type(event).__name__}\")\n",
    "        if hasattr(event, 'content'):\n",
    "            print(f\"  Content parts: {len(event.content.parts) if event.content and event.content.parts else 0}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3cf207",
   "metadata": {},
   "source": [
    "# 1.2 Shipping Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60a18a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Long-running functions created!\n"
     ]
    }
   ],
   "source": [
    "LARGE_ORDER_THRESHOLD = 5\n",
    "\n",
    "\n",
    "def place_shipping_order(\n",
    "    num_containers: int, destination: str, tool_context: ToolContext) -> dict:\n",
    "    \"\"\"Places a shipping order. Requires approval if ordering more than 5 containers (LARGE_ORDER_THRESHOLD).\n",
    "\n",
    "    Args:\n",
    "        num_containers: Number of containers to ship\n",
    "        destination: Shipping destination\n",
    "\n",
    "    Returns:\n",
    "        Dictionary with order status\n",
    "    \"\"\"\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # SCENARIO 1: Small orders (â‰¤5 containers) auto-approve\n",
    "    if num_containers <= LARGE_ORDER_THRESHOLD:\n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"order_id\": f\"ORD-{num_containers}-AUTO\",\n",
    "            \"num_containers\": num_containers,\n",
    "            \"destination\": destination,\n",
    "            \"message\": f\"Order auto-approved: {num_containers} containers to {destination}\",\n",
    "        }\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # SCENARIO 2: This is the first time this tool is called. Large orders need human approval - PAUSE here.\n",
    "    if not tool_context.tool_confirmation:\n",
    "        tool_context.request_confirmation(\n",
    "            hint=f\"âš ï¸ Large order: {num_containers} containers to {destination}. Do you want to approve?\",\n",
    "            payload={\"num_containers\": num_containers, \"destination\": destination},\n",
    "        )\n",
    "        return {  # This is sent to the Agent\n",
    "            \"status\": \"pending\",\n",
    "            \"message\": f\"Order for {num_containers} containers requires approval\",\n",
    "        }\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # SCENARIO 3: The tool is called AGAIN and is now resuming. Handle approval response - RESUME here.\n",
    "    if tool_context.tool_confirmation.confirmed:\n",
    "        return {\n",
    "            \"status\": \"approved\",\n",
    "            \"order_id\": f\"ORD-{num_containers}-HUMAN\",\n",
    "            \"num_containers\": num_containers,\n",
    "            \"destination\": destination,\n",
    "            \"message\": f\"Order approved: {num_containers} containers to {destination}\",\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            \"status\": \"rejected\",\n",
    "            \"message\": f\"Order rejected: {num_containers} containers to {destination}\",\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"âœ… Long-running functions created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e5ec04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Shipping Agent created!\n"
     ]
    }
   ],
   "source": [
    "# Create shipping agent with pausable tool\n",
    "shipping_agent = LlmAgent(\n",
    "    name=\"shipping_agent\",\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    instruction=\"\"\"You are a shipping coordinator assistant.\n",
    "  \n",
    "  When users request to ship containers:\n",
    "   1. Use the place_shipping_order tool with the number of containers and destination\n",
    "   2. If the order status is 'pending', inform the user that approval is required\n",
    "   3. After receiving the final result, provide a clear summary including:\n",
    "      - Order status (approved/rejected)\n",
    "      - Order ID (if available)\n",
    "      - Number of containers and destination\n",
    "   4. Keep responses concise but informative\n",
    "  \"\"\",\n",
    "    tools=[FunctionTool(func=place_shipping_order)],\n",
    ")\n",
    "\n",
    "print(\"âœ… Shipping Agent created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6eb2c6ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Resumable app created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aarya\\AppData\\Local\\Temp\\ipykernel_21644\\3673777575.py:5: UserWarning: [EXPERIMENTAL] ResumabilityConfig: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  resumability_config=ResumabilityConfig(is_resumable=True),\n"
     ]
    }
   ],
   "source": [
    "# Wrap the agent in a resumable app - THIS IS THE KEY FOR LONG-RUNNING OPERATIONS!\n",
    "shipping_app = App(\n",
    "    name=\"shipping_coordinator\",\n",
    "    root_agent=shipping_agent,\n",
    "    resumability_config=ResumabilityConfig(is_resumable=True),\n",
    ")\n",
    "\n",
    "print(\"âœ… Resumable app created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c3ec1033",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "App name mismatch detected. The runner is configured with app name \"shipping_coordinator\", but the root agent was loaded from \"C:\\Users\\aarya\\Desktop\\Aaryan\\Projects\\Agents\\ai-agents-workshop\\agentenv\\Lib\\site-packages\\google\\adk\\agents\", which implies app name \"agents\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Runner created!\n"
     ]
    }
   ],
   "source": [
    "session_service = InMemorySessionService()\n",
    "\n",
    "# Create runner with the resumable app\n",
    "shipping_runner = Runner(\n",
    "    app=shipping_app,  # Pass the app instead of the agent\n",
    "    session_service=session_service,\n",
    ")\n",
    "\n",
    "print(\"âœ… Runner created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9f72bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_approval(events):\n",
    "    \"\"\"Check if events contain an approval request.\n",
    "\n",
    "    Returns:\n",
    "        dict with approval details or None\n",
    "    \"\"\"\n",
    "    for event in events:\n",
    "        if event.content and event.content.parts:\n",
    "            for part in event.content.parts:\n",
    "                if (\n",
    "                    part.function_call\n",
    "                    and part.function_call.name == \"adk_request_confirmation\"\n",
    "                ):\n",
    "                    return {\n",
    "                        \"approval_id\": part.function_call.id,\n",
    "                        \"invocation_id\": event.invocation_id,\n",
    "                    }\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9e341fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Helper functions defined\n"
     ]
    }
   ],
   "source": [
    "def create_approval_response(approval_info, approved):\n",
    "    \"\"\"Create approval response message.\"\"\"\n",
    "    confirmation_response = types.FunctionResponse(\n",
    "        id=approval_info[\"approval_id\"],\n",
    "        name=\"adk_request_confirmation\",\n",
    "        response={\"confirmed\": approved},\n",
    "    )\n",
    "    return types.Content(\n",
    "        role=\"user\", parts=[types.Part(function_response=confirmation_response)]\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"âœ… Helper functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "178eb333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_agent_response(events):\n",
    "    \"\"\"Print agent's text responses from events.\"\"\"\n",
    "    for event in events:\n",
    "        if event.content and event.content.parts:\n",
    "            for part in event.content.parts:\n",
    "                if part.text:\n",
    "                    print(f\"Agent > {part.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6701aed5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Workflow function ready\n"
     ]
    }
   ],
   "source": [
    "async def run_shipping_workflow(query: str, auto_approve: bool = True):\n",
    "    \"\"\"Runs a shipping workflow with approval handling.\n",
    "\n",
    "    Args:\n",
    "        query: User's shipping request\n",
    "        auto_approve: Whether to auto-approve large orders (simulates human decision)\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"User > {query}\\n\")\n",
    "\n",
    "    # Generate unique session ID\n",
    "    session_id = f\"order_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "    # Create session\n",
    "    await session_service.create_session(\n",
    "        app_name=\"shipping_coordinator\", user_id=\"test_user\", session_id=session_id\n",
    "    )\n",
    "\n",
    "    query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "    events = []\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # STEP 1: Send initial request to the Agent. If num_containers > 5, the Agent returns the special `adk_request_confirmation` event\n",
    "    async for event in shipping_runner.run_async(\n",
    "        user_id=\"test_user\", session_id=session_id, new_message=query_content\n",
    "    ):\n",
    "        events.append(event)\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # STEP 2: Loop through all the events generated and check if `adk_request_confirmation` is present.\n",
    "    approval_info = check_for_approval(events)\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # STEP 3: If the event is present, it's a large order - HANDLE APPROVAL WORKFLOW\n",
    "    if approval_info:\n",
    "        print(f\"â¸ï¸  Pausing for approval...\")\n",
    "        print(f\"ðŸ¤” Human Decision: {'APPROVE âœ…' if auto_approve else 'REJECT âŒ'}\\n\")\n",
    "\n",
    "        # PATH A: Resume the agent by calling run_async() again with the approval decision\n",
    "        async for event in shipping_runner.run_async(\n",
    "            user_id=\"test_user\",\n",
    "            session_id=session_id,\n",
    "            new_message=create_approval_response(\n",
    "                approval_info, auto_approve\n",
    "            ),  # Send human decision here\n",
    "            invocation_id=approval_info[\n",
    "                \"invocation_id\"\n",
    "            ],  # Critical: same invocation_id tells ADK to RESUME\n",
    "        ):\n",
    "            if event.content and event.content.parts:\n",
    "                for part in event.content.parts:\n",
    "                    if part.text:\n",
    "                        print(f\"Agent > {part.text}\")\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    else:\n",
    "        # PATH B: If the `adk_request_confirmation` is not present - no approval needed - order completed immediately.\n",
    "        print_agent_response(events)\n",
    "\n",
    "    print(f\"{'='*60}\\n\")\n",
    "\n",
    "\n",
    "print(\"âœ… Workflow function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f0db9b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "User > Ship 10 containers to Rotterdam\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "c:\\Users\\aarya\\Desktop\\Aaryan\\Projects\\Agents\\ai-agents-workshop\\agentenv\\Lib\\site-packages\\google\\adk\\tools\\tool_context.py:92: UserWarning: [EXPERIMENTAL] ToolConfirmation: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  ToolConfirmation(\n",
      "c:\\Users\\aarya\\Desktop\\Aaryan\\Projects\\Agents\\ai-agents-workshop\\agentenv\\Lib\\site-packages\\google\\adk\\agents\\invocation_context.py:298: UserWarning: [EXPERIMENTAL] BaseAgentState: This feature is experimental and may change or be removed in future versions without notice. It may introduce breaking changes at any time.\n",
      "  self.agent_states[event.author] = BaseAgentState()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â¸ï¸  Pausing for approval...\n",
      "ðŸ¤” Human Decision: REJECT âŒ\n",
      "\n",
      "Agent > Order rejected: 10 containers to Rotterdam.\n",
      "============================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "await run_shipping_workflow(\"Ship 10 containers to Rotterdam\", auto_approve=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ac81d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
